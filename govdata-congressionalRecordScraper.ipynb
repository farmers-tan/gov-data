{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congressional Record (CREC) Web Scraper\n",
    "\n",
    "This notebook provides a workflow for downloading the entire U.S. Congressional Record in either HTML or PDF format, conviently made publically available by the Government Publishing Office's FDsys portal.\n",
    "\n",
    "The process is as follows:\n",
    "1. Define some years, months, and days of interest\n",
    "2. \"Click\" through the tables found here to expand a given year, month, and day: https://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CREC\n",
    "3. Extract all \"source data links\" from the inner most HTML table - both HTML and PDF format - into a list\n",
    "4. Download each of the files from that list (I use HTML for ease of parsing)\n",
    "5. Merge multi-file sessions into a single text file -  House and Senate sessions are commonly broken into multiple HTML pages (for \"ease\" of reading, or potentially, \"difficulty\" of scraping)\n",
    "6. Another notebook in this repo is available for parsing these plain text files into interesting features - monologues, inter-monologue [name] references, proper nouns, etc.\n",
    "7. Another set of scripts in this repo will load outputs from step 6. into a Neo4J database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "dcap = dict(DesiredCapabilities.PHANTOMJS)\n",
    "dcap[\"phantomjs.page.settings.userAgent\"] = \\\n",
    "        (\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36\")\n",
    "dcap[u'acceptSslCerts'] = True\n",
    "    \n",
    "driver = webdriver.PhantomJS(desired_capabilities=dcap, \n",
    "                             service_args=['--ssl-protocol=any', '--ignore-ssl-errors=true'],\n",
    "                             service_log_path=\"/Users/kyledunn/phantom.log\")\n",
    "\n",
    "driver.set_window_size(1440, 1024)\n",
    "\n",
    "def loadComplete(driver):\n",
    "    try:\n",
    "        return 'true' == driver.execute_script('retFalse()')\n",
    "    except WebDriverException:\n",
    "        pass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getHref(obj):\n",
    "    try:\n",
    "        url = obj['href']\n",
    "        return url\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def getLinkTable(year, month, day, hOrS, code=3):\n",
    "    theUrl = \"\"\"https://www.gpo.gov/fdsys/browse/collection.action?collectionCode=CREC&\"\"\" + \\\n",
    "             \"\"\"browsePath={y}%2F{m:02d}%2F{m:02d}-{d:02d}%5C%2F{n}%2F{hors}&\"\"\" + \\\n",
    "             \"\"\"isCollapsed=false&leafLevelBrowse=false&isDocumentResults=true\"\"\"\n",
    "              \n",
    "    theUrl = theUrl.format(y=year, m=month, d=day, hors=hOrS, n=code)\n",
    "    \n",
    "    #print theUrl\n",
    "    \n",
    "    #try:\n",
    "    driver.get(theUrl)\n",
    "    #except URLError as e:\n",
    "    #    print year, month, day, hOrS, e.message\n",
    "    #    return []\n",
    "\n",
    "    pageString = driver.page_source\n",
    "    \n",
    "    #print pageString\n",
    "    \n",
    "    soup = BeautifulSoup(pageString, \"html.parser\")\n",
    "    \n",
    "    return soup.find('table', {'class': 'browse-node-table'})\n",
    "\n",
    "# Scrape the CREC site for all <a> tags - i.e. links to the congressional record documents (HTML + PDF)\n",
    "def getLinks(year, month, day, hOrS):\n",
    "    # URLs change over time slightly\n",
    "    code = 2\n",
    "    expandedTable = getLinkTable(year, month, day, hOrS, code)\n",
    "    \n",
    "    while expandedTable is None and code < 6:\n",
    "        code = code + 1\n",
    "        expandedTable = getLinkTable(year, month, day, hOrS, code)\n",
    "        \n",
    "    if expandedTable is None:\n",
    "        #print year, month, day, hOrS, \"is invalid\"\n",
    "        return []\n",
    "    \n",
    "    aTags = [a for a in expandedTable.find_all('a') if a]\n",
    "\n",
    "    allLinks = map(getHref, aTags)\n",
    "\n",
    "    return allLinks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over timeframe of interest and find all links to documents (HTML and PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 14.1 s, total: 2min 13s\n",
      "Wall time: 1h 41min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Took about 1.6 hours for 9 months on a 40Mbit connection\n",
    "\n",
    "docs = { \"HOUSE\": [], \"SENATE\": [] }\n",
    "for y in range(2016, 2017):\n",
    "    for m in range(4, 13):\n",
    "        for d in range(1,32):\n",
    "            for hOrS in [\"HOUSE\", \"SENATE\"]:\n",
    "                try:\n",
    "                    docs[hOrS] = docs[hOrS] + getLinks(y, m, d, hOrS)\n",
    "                except TypeError:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the list of HTML links for restart/repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open(\"/Users/kyledunn/Desktop/congressionalRecord/links-house-10-Dec-2016.txt\", \"w\") as theFile:\n",
    "#    theFile.write(\"\\n\".join(docs[\"HOUSE\"]))\n",
    "\n",
    "#with open(\"/Users/kyledunn/Desktop/congressionalRecord/links-senate-10-Dec-2016.txt\", \"w\") as theFile:\n",
    "#    theFile.write(\"\\n\".join(docs[\"SENATE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for only HTM[L] pages, they are easier to parse than PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housePlaintext = [d for d in docs[\"HOUSE\"] if \"htm\" in d]\n",
    "senatePlaintext = [d for d in docs[\"SENATE\"] if \"htm\" in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload previously saved HTML links for restart/repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open(\"/Users/kyledunn/Desktop/congressionalRecord/textlinks-house-6-April-2016.txt\", \"w\") as theFile:\n",
    "#    theFile.write(\"\\n\".join(housePlaintext))\n",
    "\n",
    "#with open(\"/Users/kyledunn/Desktop/congressionalRecord/textlinks-senate-6-April-2016.txt\", \"w\") as theFile:\n",
    "#    theFile.write(\"\\n\".join(senatePlaintext))\n",
    "\n",
    "#senatePlaintext = []\n",
    "#with open(\"/Users/kyledunn/Desktop/congressionalRecord/textlinks-senate-6-April-2016.txt\", \"r\") as theFile:\n",
    "#    senatePlaintext = theFile.readlines()\n",
    "    \n",
    "#housePlaintext = []\n",
    "#with open(\"/Users/kyledunn/Desktop/congressionalRecord/textlinks-house-6-April-2016.txt\", \"r\") as theFile:\n",
    "#    housePlaintext = theFile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import current_process\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "def downloadAndSave(url, hOrS):\n",
    "    name = url.split(\"/\")[-1].strip()\n",
    "    filename = \"/Users/kyledunn/Desktop/congressionalRecord/{0}/{1}\".format(hOrS, name)\n",
    "    \n",
    "    # If the the file exists and isn't empty - move on\n",
    "    #if os.path.isfile(filename) and os.path.getsize(filename) > 0:\n",
    "    #    return\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    \n",
    "    html = r.text\n",
    "\n",
    "    try:\n",
    "        with open(filename, \"w\") as theFile:\n",
    "            theFile.write(html)\n",
    "    except UnicodeEncodeError:\n",
    "        print filename\n",
    "        with open(filename, \"w\") as theFile:\n",
    "            theFile.write(html.encode('utf-8'))\n",
    "        \n",
    "    \n",
    "    sleep(0.2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide up the HTML page URLs with a thread pool and get to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 29.3 s, total: 4min 3s\n",
      "Wall time: 21min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numThreads = 8\n",
    "pool = ThreadPool(numThreads)\n",
    "\n",
    "# 116 Senate sessions, 87 House took ~21 minutes\n",
    "\n",
    "results = pool.map(lambda p: downloadAndSave(p, \"HOUSE\"), housePlaintext)\n",
    "results = pool.map(lambda p: downloadAndSave(p, \"SENATE\"), senatePlaintext)\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "senateSessions = set([\"-\".join(f.split(\"/\")[-1].split(\"-\")[1:4]) for f in senatePlaintext])\n",
    "print len(senateSessions)\n",
    "houseSessions = set([\"-\".join(f.split(\"/\")[-1].split(\"-\")[1:4]) for f in housePlaintext])\n",
    "print len(houseSessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the HTML content \n",
    "Extract only text within the `<pre></pre>` element - this is the actual record text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePage(theText):\n",
    "    \n",
    "    soup = BeautifulSoup(theText, \"html.parser\")\n",
    "    \n",
    "    return \"\\n\".join(soup.find('pre').text.splitlines()[4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge together disparate sections \n",
    "A given House/Senate session can have multiple files, save them into a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mergeFiles(date, hOrS):\n",
    "    mergedFile = '/Users/kyledunn/Desktop/congressionalRecord/{0}/Merged/{1}.txt'.format(hOrS, date)\n",
    "    \n",
    "    # If the the file exists and isn't empty - move on\n",
    "    #if os.path.isfile(mergedFile) and os.path.getsize(mergedFile) > 0:\n",
    "    #    return    \n",
    "    \n",
    "    path = '/Users/kyledunn/Desktop/congressionalRecord/{0}/*{1}*.htm'.format(hOrS, date)\n",
    "    files = glob.glob(path)\n",
    "     \n",
    "    sessionText = \"\"\n",
    "    # Remove file extension from sorting to get proper order\n",
    "    for f in sorted(files, key = lambda x: x.rsplit('.', 1)[0]): \n",
    "        with open(f, \"r\") as theFile:\n",
    "            try:\n",
    "                sessionText = sessionText + parsePage(theFile.read())\n",
    "            except AttributeError:\n",
    "                print f, \"failed to parse\"\n",
    "                \n",
    "    \n",
    "    try:\n",
    "        with open(mergedFile, \"w\") as theFile:\n",
    "            theFile.write(sessionText)\n",
    "    except UnicodeEncodeError:\n",
    "        with open(mergedFile, \"w\") as theFile:\n",
    "            theFile.write(sessionText.encode('utf-8'))\n",
    "    \n",
    "    #print sessionText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide up the sessions (one per day) with a thread pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 7.23 s, total: 23.8 s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numThreads = 8\n",
    "pool = ThreadPool(numThreads)\n",
    "\n",
    "# Took about 2.5 minutes for ~200 sessions\n",
    "\n",
    "hResults = pool.map(lambda d: mergeFiles(d, \"HOUSE\"), houseSessions)\n",
    "sResults = pool.map(lambda d: mergeFiles(d, \"SENATE\"), senateSessions)\n",
    "\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "senateSessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually specify some pages to re-do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kyledunn/Desktop/congressionalRecord/HOUSE/CREC-2011-12-06-pt1-PgH8153.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/HOUSE/CREC-2000-03-23-pt1-PgH1330-2.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/HOUSE/CREC-2014-12-11-pt2-PgH9307-2.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/HOUSE/CREC-2015-05-14-pt1-PgH2999-3.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/HOUSE/CREC-2007-12-17-pt2-PgH15741.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-2007-05-24-pt1-PgS6837.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-2008-09-22-pt1-PgS9197-2.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-2008-02-29-pt1-PgS1393-7.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-2001-07-24-pt1-PgS8121.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-2002-02-26-pt1-PgS1141-2.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-1996-03-20-pt1-PgS2341-6.htm\n",
      "/Users/kyledunn/Desktop/congressionalRecord/SENATE/CREC-2001-05-09-pt1-PgS4773-2.htm\n"
     ]
    }
   ],
   "source": [
    "redoH = [\n",
    "    \"CREC-2015-05-14-pt1-PgH2999-3.htm\",\n",
    "    \"CREC-2007-12-17-pt2-PgH15741.htm\",\n",
    "    \"CREC-2014-12-11-pt2-PgH9307-2.htm\",\n",
    "    \"CREC-2000-03-23-pt1-PgH1330-2.htm\",\n",
    "    \"CREC-2011-12-06-pt1-PgH8153.htm\"\n",
    "]\n",
    "\n",
    "redoS = [\n",
    "    \"CREC-2001-05-09-pt1-PgS4773-2.htm\",\n",
    "    \"CREC-2008-09-22-pt1-PgS9197-2.htm\",\n",
    "    \"CREC-2001-07-24-pt1-PgS8121.htm\",\n",
    "    \"CREC-2007-05-24-pt1-PgS6837.htm\",\n",
    "    \"CREC-2008-02-29-pt1-PgS1393-7.htm\",\n",
    "    \"CREC-1996-03-20-pt1-PgS2341-6.htm\",\n",
    "    \"CREC-2002-02-26-pt1-PgS1141-2.htm\" \n",
    "]\n",
    "\n",
    "hRedoUrls = [u for u in housePlaintext if u.split(\"/\")[-1][:-1] in redoH]\n",
    "sRedoUrls = [u for u in senatePlaintext if u.split(\"/\")[-1][:-1] in redoS]\n",
    "\n",
    "#print len(hRedoUrls), len(sRedoUrls)\n",
    "\n",
    "numThreads = 8\n",
    "\n",
    "def makeBrowser(id):\n",
    "    dcap = dict(DesiredCapabilities.PHANTOMJS)\n",
    "    dcap[\"phantomjs.page.settings.userAgent\"] = \\\n",
    "            (\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:32.0) Gecko/20100101 Firefox/32.0\")\n",
    "\n",
    "    driver = webdriver.PhantomJS(desired_capabilities=dcap, \n",
    "                                 service_args=['--ignore-ssl-errors=true', '--ssl-protocol=tlsv1'],\n",
    "                                 service_log_path=\"/Users/kyledunn/phantom-{0}.log\".format(id))\n",
    "\n",
    "    driver.set_window_size(1440, 1024)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "pool = ThreadPool(numThreads)\n",
    "\n",
    "#browsers = [makeBrowser(i) for i in range(numThreads)]\n",
    "threadIds = list(set(pool.map(lambda p : current_process().ident, range(4*numThreads))))\n",
    "browserRefs = dict(zip(threadIds, browsers))\n",
    "\n",
    "results = pool.map(lambda p: downloadAndSave(browserRefs, p, \"HOUSE\"), hRedoUrls)\n",
    "results = pool.map(lambda p: downloadAndSave(browserRefs, p, \"SENATE\"), sRedoUrls)\n",
    "\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hRedoSessions = [\"2011-12-06\", \"2000-03-23\", \"2014-12-11\", \"2015-05-14\", \"2007-12-17\"]\n",
    "sRedoSessions = [\"20080229\"]\n",
    "\n",
    "numThreads = 1\n",
    "pool = ThreadPool(numThreads)\n",
    "\n",
    "#hResults = pool.map(lambda d: mergeFiles(d, \"HOUSE\"), hRedoSessions)\n",
    "sResults = pool.map(lambda d: mergeFiles(d, \"SENATE\"), sRedoSessions)\n",
    "\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
